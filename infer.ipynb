{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "\n",
    "eff_l = timm.create_model(\n",
    "    \"tf_efficientnetv2_l.in21k\",\n",
    "    pretrained=False,\n",
    "    num_classes=107,\n",
    "    features_only=False,\n",
    ")\n",
    "\n",
    "convnext = timm.create_model(\n",
    "    \"convnext_large.fb_in22k\",\n",
    "    pretrained=False,\n",
    "    num_classes=107,\n",
    "    features_only=False,\n",
    "    # drop_path_rate=0.2,\n",
    "    drop_rate=0.4,\n",
    ")\n",
    "effvit = timm.create_model(\n",
    "    \"timm/efficientvit_l3.r384_in1k\",\n",
    "    pretrained=False,\n",
    "    num_classes=107,  # 107\n",
    "    features_only=False,\n",
    "    # drop_path_rate=0.2,\n",
    "    drop_rate=0.4,\n",
    ")\n",
    "\n",
    "from model import DualModel\n",
    "\n",
    "model = DualModel()\n",
    "\n",
    "from pl_tool import LightningModule\n",
    "from option import get_option\n",
    "\n",
    "opt = get_option()\n",
    "Model = LightningModule(opt, model, 1)\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义随机裁剪和线性调整大小的变换\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(size=(336, 336)),\n",
    "        transforms.Resize(\n",
    "            size=(384, 384), interpolation=transforms.InterpolationMode.BILINEAR\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_list, transform=None):\n",
    "        self.test_list = test_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.test_list[idx]\n",
    "        img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        return img, path\n",
    "\n",
    "\n",
    "test_path = \"/home/ubuntu/Competition/XunFeiAnimal/data2/testA\"\n",
    "test_list = glob.glob(test_path + \"/*.jpg\")\n",
    "test_list = sorted(test_list)\n",
    "\n",
    "\n",
    "ckpt_list = (\n",
    "    glob.glob(\n",
    "        \"./checkpoints/dual_effv2_l_effvit_l3_data2V3_4fold_m3_dp\" + \"/epoch*.ckpt\"\n",
    "    )\n",
    "    # + glob.glob(\"./checkpoints/effvit_l3_data2V3_4fold_m3_0.95161\" + \"/epoch*.ckpt\")\n",
    "    # + glob.glob(\"./checkpoints/effv2_l_data2V3_5_6fold_0.94656\" + \"/*epoch*.ckpt\")\n",
    "    # + glob.glob(\"./checkpoints/effv2_l_data2V3_5fold_0.94265\" + \"/*epoch*.ckpt\")\n",
    "    # + glob.glob(\"./checkpoints/effvit_l3_data2V3_4fold_m5_0.94154\" + \"/*epoch*.ckpt\")\n",
    ")\n",
    "\n",
    "# Store predictions for each checkpoint\n",
    "all_predictions = []\n",
    "\n",
    "for ckpt_path in ckpt_list:\n",
    "    print(f\"Loading checkpoint {ckpt_path}\")\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    for k, v in list(ckpt[\"state_dict\"].items()):\n",
    "        if \"model.\" in k:\n",
    "            ckpt[\"state_dict\"][k[6:]] = ckpt[\"state_dict\"].pop(k)\n",
    "\n",
    "    if \"dual\" in ckpt_path:\n",
    "        model = Model\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    elif \"effv2_l\" in ckpt_path:\n",
    "        model = eff_l\n",
    "    elif \"convnext\" in ckpt_path:\n",
    "        model = convnext\n",
    "    elif \"effvit\" in ckpt_path:\n",
    "        model = effvit\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model = model.cuda(4)\n",
    "    model.eval()\n",
    "    test_dataset = TestDataset(test_list, transform=valid_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for img, name in test_loader:\n",
    "            img = img.cuda(4)\n",
    "            # 初始化预测结果\n",
    "            pred = (\n",
    "                torch.softmax(model(img), dim=1)\n",
    "                + torch.softmax(model(img.flip(-1)), dim=1)\n",
    "                + torch.softmax(model(img.flip(-2)), dim=1)\n",
    "                + torch.softmax(model(img.flip(-1, -2)), dim=1)\n",
    "            )\n",
    "\n",
    "            # 应用TTA\n",
    "            for _ in range(5):  # 假设进行5次随机裁剪和调整大小\n",
    "                augmented_img = transform(img)\n",
    "                pred += (\n",
    "                    torch.softmax(model(augmented_img), dim=1)\n",
    "                    + torch.softmax(model(augmented_img.flip(-1)), dim=1)\n",
    "                    + torch.softmax(model(augmented_img.flip(-2)), dim=1)\n",
    "                    + torch.softmax(model(augmented_img.flip(-1, -2)), dim=1)\n",
    "                )\n",
    "            # 计算预测类别\n",
    "            pred_class = torch.argmax(pred, dim=1).cpu().numpy()\n",
    "            predictions.extend(pred_class)\n",
    "\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# 对所有 checkpoint 的预测结果进行投票\n",
    "final_predictions = []\n",
    "for i in range(len(test_list)):\n",
    "    votes = [pred[i] for pred in all_predictions]\n",
    "    final_predictions.append(Counter(votes).most_common(1)[0][0])\n",
    "\n",
    "print(final_predictions)\n",
    "test_list = [path.split(\"/\")[-1] for path in test_list]\n",
    "final_predictions = [str(x + 1) for x in final_predictions]\n",
    "df = pd.DataFrame({\"uuid\": test_list, \"label\": final_predictions})\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "test_list = [os.path.basename(path) for path in test_list]\n",
    "df = pd.DataFrame({\"ImageID\": test_list, \"label\": final_predictions})\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
